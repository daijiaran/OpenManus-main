# 全局 LLM 配置
[llm] # 方舟平台豆包模型配置
api_type = "doubao"                                                    # 方舟平台豆包兼容标识
model = "doubao-seed-1-6-251015"                                       # 你的方舟模型ID
base_url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions" # 方舟API端点
api_key = "a1768b58-3faf-4298-8490-66dd37e40483"                       # 你的方舟API密钥
max_tokens = 8192                                                      # 响应最大token数
temperature = 0.0                                                      # 控制随机性（0-1之间）

# [llm] # Claude 配置（已注释）
# model = "claude-3-7-sonnet-20250219"
# base_url = "https://api.anthropic.com/v1/"
# api_key = "YOUR_API_KEY"
# max_tokens = 8192
# temperature = 0.0

# [llm] # Amazon Bedrock（已注释）
# api_type = "aws"
# model = "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
# base_url = "bedrock-runtime.us-west-2.amazonaws.com"
# max_tokens = 8192
# temperature = 1.0
# api_key = "bear"

# [llm] # AZURE OPENAI（已注释）
# api_type= 'azure'
# model = "YOUR_MODEL_NAME"
# base_url = "{YOUR_AZURE_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPLOYMENT_ID}"
# api_key = "AZURE API KEY"
# max_tokens = 8096
# temperature = 0.0
# api_version="2024-08-01-preview"

# [llm] # OLLAMA（已注释）
# api_type = 'ollama'
# model = "llama3.2"
# base_url = "http://localhost:11434/v1"
# api_key = "ollama"
# max_tokens = 4096
# temperature = 0.0

# 可选配置：特定 LLM 模型配置（视觉模型）
[llm.vision] # 方舟平台豆包视觉模型配置
api_type = "doubao"
model = "doubao-seed-1-6-251015"                                       # 你的方舟视觉模型ID（若有差异请替换）
base_url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
api_key = "a1768b58-3faf-4298-8490-66dd37e40483"                       # 与上面的API密钥一致
max_tokens = 8192
temperature = 0.0

# [llm.vision] # OLLAMA 视觉模型（已注释）
# api_type = 'ollama'
# model = "llama3.2-vision"
# base_url = "http://localhost:11434/v1"
# api_key = "ollama"
# max_tokens = 4096
# temperature = 0.0

# 可选配置：浏览器配置
# [browser]
# 是否以无头模式运行浏览器（默认: false）
#headless = false
# 禁用浏览器安全功能（默认: true）
#disable_security = true
# 传递给浏览器的额外参数
#extra_chromium_args = []
# 用于连接到您的普通浏览器的 Chrome 实例路径
#chrome_instance_path = ""
# 通过 WebSocket 连接到浏览器实例
#wss_url = ""
# 通过 CDP 连接到浏览器实例
#cdp_url = ""

# 可选配置：浏览器的代理设置
# [browser.proxy]
# server = "http://proxy-server:port"
# username = "proxy-username"
# password = "proxy-password"

# 可选配置：搜索设置
# [search]
# 代理要使用的搜索引擎。默认为 "Google"，可设置为 "Baidu"、"DuckDuckGo" 或 "Bing"
#engine = "Google"
# 备用引擎顺序。默认为 ["DuckDuckGo", "Baidu", "Bing"]
#fallback_engines = ["DuckDuckGo", "Baidu", "Bing"]
# 当所有引擎因速率限制都失败后，重试前等待的秒数。默认为 60
#retry_delay = 60
# 当所有引擎都失败时，最大重试次数。默认为 3
#max_retries = 3
# 搜索结果的语言代码
#lang = "en"
# 搜索结果的国家代码
#country = "us"

## 沙箱配置
#[sandbox]
#use_sandbox = false
#image = "python:3.12-slim"
#work_dir = "/workspace"
#memory_limit = "1g"
#cpu_limit = 2.0
#timeout = 300
#network_enabled = true

# MCP (Model Context Protocol) 配置
[mcp]
server_reference = "app.mcp.server" # 默认服务器模块引用

# 可选的 Runflow 配置
# [runflow]
#use_data_analysis_agent = false # 数据分析代理
